---
title: "UGIC Workshop: 02 Spatial data in R Part 2"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'UGIC_Workshop_02_Spatial_Data_2.html'))})
author: | 
  | Simon Brewer and Blake Vernon
  | Geography and Anthropology Departments
  | University of Utah
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    fig_caption: true
---

```{r include = FALSE}

knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")

```

We'll carry on looking at spatial data in this lab. You should have the following files from the previous lab, but it's worth checking to make sure you have everything: 

- Climate dataset for Western North America: *WNAclimate.csv*
- Temperature dataset for Oregon in shapefile format: *oregon.zip*
- New York state polygon data in a shapefile: *NY_Data.zip*
- Digital elevation map from Switzerland: *swiss_dem.grd*
- A NetCDF file of global monthly air temperature: *air.mon.ltm.nc*
- A NetCDF file of global monthly mean air temperature: *air.mon.mean.nc*
- A dataset of country socioeconomic variables: *countries.zip*

Base R has no structure for spatial data, so you will need to install the following packages (you should have some of these from previous modules):

- **sf**
- **terra**
- **RColorBrewer**
- **ggplot2**
- **viridis**

```{r, message = FALSE, warning=FALSE}

library(ggplot2)
library(terra)
library(RColorBrewer)
library(sf)
library(viridis)

```

# Raster data

Previously, we were working with _vector_ spatial data. These are geometries composed of points defined by their coordinates. An alternative form of spatial data is known as a _raster_. This is gridded data. It takes the form of a rectangle composed of squares of equal size, which are sometimes called 'cells' or 'pixels'. Each cell stores some kind of value. 

This simplifies the geometry, which can be specified by two pieces of information: the spatial extent of the raster and the resolution of the cells. Here we create a blank raster with 10 rows and 10 columns, with a resolution of 10x10 using the `rast()` function. We then assign random values to each cell:

```{r, echo = TRUE}

r <- rast(nrow = 10, ncol = 10, 
          xmin = 0, xmax = 100, 
          ymin = 0, ymax = 100)

r[] <- runif(n = 100)

r
```

`rast` objects can be plotted using the base `plot()` command:

```{r}

plot(r)

```

The **terra** package offers a wide array of functions for dealing with gridded data, including the ability to read from many widely used file formats, like remote sensing images (e.g. GeoTiffs), NetCDF, and HDF formats. We will use it here to work with a Landsat 8 scene collected on June 14, 2017. The subset covers the area between Concord and Stockton, in California, USA. The files are contained in the zip file *rs.zip*. Download this (if you haven't already) and unzip it in your `data` folder. 

We will also need the shapefile of California places (*ca_places.zip*), so download and unzip this as well. We'll read this in before starting:

```{r}

ca_places <- st_read("./data/ca_places/ca_places.shp")

```

<br>

## Read and Write Rasters

To read in gridded data, use the `rast()` function. This will read in the Near Infrared (NIR) channel (`B5`)

```{r, eval = TRUE}

b5 <- rast("./data/rs/LC08_044034_20170614_B5.tif")

b5

```

When we print the `rast` object created, the second line of the output lists the dimensions of the data. Note that here, this has 1245 rows, 1497 columns and 1 layer. This also shows the resolution (30x30 m), the extent, the CRS and the a brief summary of the data. 

We can write `rast` objects back to file using `writeRaster()` (I'll bet you never thought it would be called that). You can write out to any format supported by [GDAL][gdalfiles]. Here we write out to a TIFF format. You can see the full list of available formats for reading and writing by running the `writeFormats()` function in the console. We'll use this again after having worked with the data.

```{r, eval = FALSE}

writeRaster(b5, 
            filename = "./b5.tif",
            overwrite = TRUE)

```


<br>

## Raster CRS

As with the `sf` objects, we can check the coordinate reference system of the file we just read. This does not print very well, but if you look at the end you'll see a reference to the EPSG code (32610). 

```{r, message = FALSE, warning = FALSE}

crs(b5)

```

If the CRS is not set, you can set it using the `crs()` function and an EPSG code. For example, the following code would set the CRS to WGS84 (**don't run this as the CRS is already defined**)

```{r, message = FALSE, warning = FALSE, eval = FALSE}

crs(b5) <- "EPSG:4326"

```

Again, this should not be used to _change_ the CRS, only set it. Note that `crs` is for `rast` objects, `st_crs` for vectors. 

<br>

You can transform the CRS for a raster layer using `project()`. This can again use a EPSG type code. 

```{r, warning = FALSE}

b5_wgs84 <- project(b5, "EPSG:4326")

crs(b5_wgs84)

```

We'll keep the Landsat data in its UTM projection (10N), and reproject the CA place data to match:

```{r}

ca_places <- st_transform(ca_places, 32610)

```

<br>

## Basic Plotting

You can make a simple plot using the `plot()` function:

```{r}

plot(b5, main = "Landsat 8 (B2)")

plot(st_geometry(ca_places), add = TRUE)

```

<br>

## Summary Statistics

The function `cellStats()` can be used to calculate most summary statistics for a raster layer. So to get the mean global temperature (and standard deviation):

```{r}

global(b5, mean)

global(b5, sd)

```

<br>

## Subset Rasters

If we want to use only a subset of the original raster layer, the function `crop()` will extract only the cells in a given region. This can be defined using another raster object or Spatial* object, or by defining an `extent` object:

```{r}

# extent method
my_ext <- ext(c(xmin = 612500, 
                    xmax = 617500, 
                    ymin = 4196000,
                    ymax = 4201000))

b5_sub <- crop(b5, my_ext)

plot(b5_sub)

```

We can also use an `sf` object to crop the data. Here, we'll extract the polygon for Bethel Island from the `ca_places` object, and use this to crop the raster:

```{r}

bethel <- ca_places %>% 
  dplyr::filter(NAME == "Bethel Island")

b5_sub <- crop(b5, bethel)

plot(b5_sub)
plot(st_geometry(bethel), add = TRUE)

```

Note that `crop` subsets the original raster to the extent of Canada's borders, rather than to the borders themselves. This is because rasters are _always_ rectangular. You can 'hide' the values of raster cells outside of a polygon by using the `mask` function. The raster has to be rectangular, so this does not remove the cells outside the polygon. Rather, it sets their value to `NA`. 

```{r}

b5_sub <- mask(b5_sub, mask = bethel)

plot(b5_sub)
plot(st_geometry(bethel), add = TRUE)

```

## Extract Data

Values can be extracted from individual locations (or sets of locations) using `extract()`. This can take a set of coordinates in matrix form, or use a Spatial* object. To get the reflectance value at 615000 E, 4199000 N:

```{r}

extract(b5, cbind(615000,4199000))

```

You can also extract for multiple locations. Let's generate a set of random points in Bethel Island, and then sample the reflectance value for each of these. 

```{r}

random_pnts <- st_sample(bethel, size = 20)

extract(b5, st_coordinates(random_pnts))

```

You can also extract values within a polygon, by replacing the point coordinates with a `sf` polygon:

```{r}

b5_bethel <- extract(b5, bethel)

head(b5_bethel)

```

By default, this returns the value of all pixels within the polygon. By adding the `fun=` argument, you can easily calculate summary statistics:

```{r}

extract(b5, bethel, fun = 'median')

```

Note that if the `sf` object has multiple polygons, it will return the summary statistic for each one. Let's now extract the values for a different place (Oakley), and then we can compare them. We do this in a couple of steps. First get the polygon for Oakley, then extract using the two polygons combined.

```{r}

oakley <- ca_places %>% 
  dplyr::filter(NAME == "Oakley")

b5_bethel_oakley <- extract(b5, rbind(bethel, oakley))

names(b5_bethel_oakley) <- c("ID", "B5")

```

We'll visualize the difference with **ggplot2**, which shows higher NIR reflectance values for Bethel, likely indicating higher vegetation cover.

```{r}

ggplot(b5_bethel_oakley, aes(x = B5, fill = as.factor(ID))) +
  geom_histogram(alpha = 0.7, position = 'identity')

```


<br>

# Raster Stacks

The `b2` raster represents a single band from the Landsat 8 scene. More usefully, we can load several bands and combine them into a single object. Here, we'll load the blue (B2), green (B3), red (B4), and infrared (B5) bands :

```{r}
# Blue
b2 <- rast('data/rs/LC08_044034_20170614_B2.tif')
# Green
b3 <- rast('data/rs/LC08_044034_20170614_B3.tif')
# Red
b4 <- rast('data/rs/LC08_044034_20170614_B4.tif')
# Near Infrared (NIR)
b5 <- rast('data/rs/LC08_044034_20170614_B5.tif')
```

Now we'll create a raster stack with all 4 of these:

```{r}

s <- c(b5, b4, b3, b2)

s

```

The metadata now shows that this contains 4 layers. You can also make the stack directly by passing a list of file names:

```{r}

filenames <- paste0('./data/rs/LC08_044034_20170614_B', 1:11, ".tif")

landsat <- rast(filenames)

landsat

```

This now contains all bands representing reflection intensity in the following wavelengths: Ultra Blue, Blue, Green, Red, Near Infrared (NIR), Shortwave Infrared (SWIR) 1, Shortwave Infrared (SWIR) 2, Panchromatic, Cirrus, Thermal Infrared (TIRS) 1, Thermal Infrared (TIRS) 2.

If we now use the `extract()` function with this object, it will return values for all bands in the stack:

```{r}

extract(landsat, cbind(615000,4199000))

```

```{r}
par(mfrow = c(2,2))
plot(b2, main = "Blue", col = gray(0:100 / 100))
plot(b3, main = "Green", col = gray(0:100 / 100))
plot(b4, main = "Red", col = gray(0:100 / 100))
plot(b5, main = "NIR", col = gray(0:100 / 100))
```

The values in each layer range from 0 to 1, and the same scale has been used for each band, showing clearly the difference in reflectance for this set of wavelengths. For example, vegetation reflects more energy in NIR than other wavelengths and thus appears brighter. In contrast, water absorbs most of the energy in the NIR wavelength and it appears dark

# Composite images

The bands can be combined to form composite images. Here, we'll use the red, green and blue bands make a true color image. This uses the concatenation function (`c()`), and the order of the bands is important (R, then G, then B):

```{r}

landsatRGB <- c(b4, b3, b2)

plotRGB(landsatRGB, stretch = "lin")

```

We can also make a false color composite with the NIR, red and green bands, where bright reds indicate vegetation cover:

Another popular image visualization method in remote sensing is known "false color" image in which NIR, red, and green bands are combined. This representation is popular as it makes it easy to see the vegetation (in red).

```{r}

landsatFCC <- c(b5, b4, b3)
plotRGB(landsatFCC, stretch="lin")

```
# Raster algebra

**terra** makes it easy to carry out simple raster algebraic operations. Eahc band or layer is treated a 2D array which makes it possible to add, subtract, multiply, divide, etc. As a simple example here, we can calculate the NDVI for the Landsat scene as 

\[
NDVI = (NIR - R) / (NIR + R)
\]

NIR is band 5 and red is band 4:


```{r}

ndvi <- (b5 - b4) / (b5 + b4)

plot(ndvi, col=rev(terrain.colors(10)), main = "NDVI")

```

We can also make a quick histogram of values to look for any outliers:

```{r}

hist(ndvi, main = "NDVI")

```

We can then use the results to carry out some simple classification.

- Vegetation (NDVI > 0.4). The `clamp` function masks all value otuside of a range (here below 0.4)

```{r}

veg = clamp(ndvi, lower=0.4, values=FALSE)

plot(veg)

```

- Croplands (corresponding to the peak in NDVI values):

```{r}

crops = ndvi > 0.25 & ndvi < 0.3 

plot(crops)

```


And water bodies (NDVI < 0):

```{r}

water = ndvi < 0

plot(water)

```

# Mapping packages

## Mapview

## TMap

## Leaflet



----
[projID]: http://trac.osgeo.org/proj/
[ncarID]: http://www.esrl.noaa.gov/psd/data/reanalysis/reanalysis.shtml
[cenID]: http://proximityone.com/cen2010_plfile.htm
[sfID]: https://r-spatial.github.io/sf/articles/sf1.html
[epsgID]: http://spatialreference.org/ref/epsg/
[colBrewID]: http://colorbrewer2.org
[iconID]: https://sites.google.com/site/gmapsdevelopment/
[natEarthID]: https://www.naturalearthdata.com
[tmapID]: https://cran.r-project.org/web/packages/tmap/
[gdalfiles]: https://gdal.org/drivers/raster/index.html